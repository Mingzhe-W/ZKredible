{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilQ4ttNFnXqq"
      },
      "source": [
        "# ZKredible\n",
        "This notebook illustrate the idea of ZK lending.\n",
        "\n",
        "some introduction to be added\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTRHxNAtnXqs"
      },
      "source": [
        "## Setup\n",
        "\n",
        "install and import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFEaWzrIndPa",
        "outputId": "57721831-4420-40f2-f53f-6696d80530f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9JQgNNxnXqt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "\n",
        "# those are optional and are not necessary for training\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fo7k607nXqu"
      },
      "source": [
        "We use the dataset for credit score classification from [kaggle](https://www.kaggle.com/datasets/parisrohan/credit-score-classification/data?select=train.csv).\n",
        "\n",
        "We already clean the data and for the purpose of clarity, we won't show the cleaning process here. You can check the data cleaning part in our code base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4M-Nux7nXqv",
        "outputId": "de48a141-a7ab-41df-ec9b-3d3c99b1a8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train has shape: torch.Size([1400, 39])\n",
            "y_train has shape: torch.Size([1400, 1])\n",
            "x_test has shape: torch.Size([600, 39])\n",
            "y_test has shape: torch.Size([600, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-a682645ef70d>:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  data = data.drop(\"Credit_Score\", \"columns\")\n"
          ]
        }
      ],
      "source": [
        "torch.random.manual_seed(919)\n",
        "random.seed(919)\n",
        "\n",
        "\n",
        "def split_train_test(x, y, test_ratio=0.3):\n",
        "    idxs = [i for i in range(len(x))]\n",
        "    random.shuffle(idxs)\n",
        "    # delimiter between test and train data\n",
        "    delim = int(len(x) * test_ratio)\n",
        "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
        "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
        "\n",
        "\n",
        "def credit_data():\n",
        "    data = pd.read_csv(\"data/cleaned_data.csv\")\n",
        "    # we use credit score as label.\n",
        "    y = torch.tensor(data['Credit_Score'].values.astype(np.single)).unsqueeze(1)\n",
        "    data = data.drop(\"Credit_Score\", \"columns\")\n",
        "\n",
        "    x = torch.tensor(data.values.astype(np.single))\n",
        "\n",
        "    return split_train_test(x, y)\n",
        "\n",
        "x_train, y_train, x_test, y_test = credit_data()\n",
        "\n",
        "print(f\"x_train has shape: {x_train.shape}\")\n",
        "print(f\"y_train has shape: {y_train.shape}\")\n",
        "print(f\"x_test has shape: {x_test.shape}\")\n",
        "print(f\"y_test has shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBL-gRBynXq3"
      },
      "source": [
        "#### Update Rule\n",
        "\n",
        "For updating the parameter, the usual rule is as follows, where $x^{(i)}$ is the i'th input data:\n",
        "\n",
        "$$\\theta_j = \\theta_j - \\alpha \\; [ \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)}) x^{(i)} + \\frac{\\lambda}{m} \\theta_j]$$\n",
        "\n",
        "However, due to homomorphic encryption constraint, we preferred to use an $\\alpha = 1$ to reduce a multiplication and set $\\frac{\\lambda}{m} = 0.05$ which gets us to the following update rule:\n",
        "\n",
        "$$\\theta_j = \\theta_j - [ \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)}) x^{(i)} + 0.05 \\theta_j]$$\n",
        "\n",
        "#### Sigmoid Approximation\n",
        "\n",
        "Since we can't simply compute sigmoid on encrypted data, we need to approximate it using a low degree polynomial, the lower the degree the better, as we aim to perform as few multiplications as possible, to be able to use smaller parameters and thus optimize computation. This tutorial uses a degree 3 polynomial from https://eprint.iacr.org/2018/462.pdf, which approximates the sigmoid function in the range $[-5,5]$.\n",
        "\n",
        "$$\\sigma(x) = 0.5 + 0.197 x - 0.004 x^3$$\n",
        "\n",
        "#### Homomorphic Encryption Parameters\n",
        "\n",
        "From the input data to the parameter update, a ciphertext will need a multiplicative depth of 6, 1 for the dot product operation, 2 for the sigmoid approximation, and 3 for the backpropagation phase (one is actually hidden in the `self._delta_w += enc_x * out_minus_y` operation in the `backward()` function, which is multiplying a 1-sized vector with an n-sized one, which requires masking the first slot and replicating it n times in the first vector). With a scale of around 20 bits, we need 6 coefficients modulus with the same bit-size as the scale, plus the last coefficient, which needs more bits, we are already out of the 4096 polynomial modulus degree (which requires < 109 total bit count of the coefficients modulus, if we consider 128-bit security), so we will use 8192. This will allow us to batch up to 4096 values in a single ciphertext, but we are far away from this limitation, so we shouldn't even think about it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "asz6OsBBnXq4"
      },
      "outputs": [],
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, n_features):\n",
        "        model = torch.nn.Linear(n_features, 1)\n",
        "        self.weight = model.weight.data.tolist()[0]\n",
        "        self.bias = model.bias.data.tolist()\n",
        "        # we accumulate gradients and counts the number of iterations\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
        "        # update weights\n",
        "        # We use a small regularization term to keep the output\n",
        "        # of the linear layer in the range of the sigmoid approximation\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # We use the polynomial approximation of degree 3\n",
        "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
        "        # from https://eprint.iacr.org/2018/462.pdf\n",
        "        # which fits the function pretty well in the range [-5,5]\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        # evaluate accuracy of the model on\n",
        "        # the plain (x_test, y_test) dataset\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "4nSMEp0bnXq4"
      },
      "outputs": [],
      "source": [
        "# parameters to achive 128 bit security, per claimed\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "# create TenSEALContext\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBR9QhLLnXq4",
        "outputId": "8510b431-e70f-43e7-f901-3cda53592678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encryption of the training_set took 37 seconds\n"
          ]
        }
      ],
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH6LdQnsnXq7",
        "outputId": "370789c2-1563-4192-d8ad-6fe3af34eff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n",
            "torch.FloatTensor\n",
            "Accuracy at epoch #1 is 0.7300000190734863\n",
            "[105841671.45342314, 37590.63030239445, -19.736270493926774, 17195.110922071777, 15691.550939873187, -1454.721696131865, -969.1268472571969, -856.9531764324754, 6347.122610045073, 12710.216949949197, -2947.8271711040716, 10449.337807999636, 2970.5026684256563, 11814.95195592563, 302.9028142883926, 22088.588437983388, 24803.365632282497, 20864.870811068664, 2838.9520160034217, 8274.002528775658, 2117.929234589493, 4853.174173993653, 1327.5063719009408, 5715.735938563395, 5589.049024375214, 4156.481528692245, 7438.729170407365, 6402.973733492752, 3766.505956049865, 3644.533162017821, 1872.806829347397, 4954.057095472459, 1862.945450672039, 8527.567065488533, 14558.552761394449, 9585.949095984868, 5501.117199719318, 9306.489230837677, 17351.52238239749]\n",
            "[24263.788741506833]\n"
          ]
        }
      ],
      "source": [
        "n_features = x_train.shape[1]\n",
        "print(n_features)\n",
        "encrypted_logistic = EncryptedLR(n_features)\n",
        "\n",
        "times = []\n",
        "\n",
        "print(x_test.type())\n",
        "\n",
        "## temp\n",
        "EPOCHS=1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    encrypted_logistic.encrypt(ctx_training)\n",
        "\n",
        "    # if you want to keep an eye on the distribution to make sure\n",
        "    # the function approximation is still working fine\n",
        "    # WARNING: this operation is time consuming\n",
        "    # encrypted_out_distribution(eelr, enc_x_train)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = encrypted_logistic.forward(enc_x)\n",
        "        encrypted_logistic.backward(enc_x, enc_out, enc_y)\n",
        "    encrypted_logistic.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    encrypted_logistic.decrypt()\n",
        "    accuracy = encrypted_logistic.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(encrypted_logistic.weight)\n",
        "print(encrypted_logistic.bias)\n",
        "\n",
        "\n",
        "# print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "# print(f\"Final accuracy is {accuracy}\")\n",
        "\n",
        "# diff_accuracy = plain_accuracy - accuracy\n",
        "# print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
        "# if diff_accuracy < 0:\n",
        "#     print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaYP4kHzyocK"
      },
      "source": [
        "## Comparision with plain Logistic Regression Model\n",
        "Now let's train a plain logistic regression model with pytorch and compare the result with model trained with homomorphic encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k8pczKf4Ho6",
        "outputId": "7b62ff8f-e669-4234-aa92-f3fe49f454ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at epoch 1: 31.254297256469727\n",
            "Loss at epoch 2: 27.71476936340332\n",
            "Loss at epoch 3: 27.71476936340332\n",
            "Loss at epoch 4: 27.71476936340332\n",
            "Loss at epoch 5: 27.71476936340332\n",
            "Accuracy of plain model on test_set: 0.7300000190734863\n"
          ]
        }
      ],
      "source": [
        "class LogisticModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_features):\n",
        "        super(LogisticModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.linear(x))\n",
        "        return out\n",
        "\n",
        "# defining model, optimizer and loss function\n",
        "n_features = x_train.shape[1]\n",
        "plain_logistic = LogisticModel(n_features)\n",
        "optim = torch.optim.SGD(plain_logistic.parameters(), lr=0.4)\n",
        "lossf = torch.nn.BCELoss()\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "# training process\n",
        "for epoch in range(EPOCHS):\n",
        "    optim.zero_grad()\n",
        "    out = plain_logistic(x_train)\n",
        "    loss = lossf(out, y_train)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    print(f\"Loss at epoch {epoch + 1}: {loss.data}\")\n",
        "\n",
        "\n",
        "# print(plain_logistic.linear.weight)\n",
        "# print(plain_logistic.linear.bias)\n",
        "\n",
        "# calculate the accuracy\n",
        "def accuracy(model, x, y):\n",
        "    out = model(x)\n",
        "    correct = torch.abs(y - out) < 0.5\n",
        "    return correct.float().mean()\n",
        "\n",
        "plain_accuracy = accuracy(plain_logistic, x_test, y_test)\n",
        "print(f\"Accuracy of plain model on test_set: {plain_accuracy}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wf6FTtAnXq8"
      },
      "source": [
        "# Convert encrypted model to ONNX format and thus can be feed into EZKL\n",
        "\n",
        "Now we do a conversion, unfortunately there is no elegant way to do so, as tenseal does not natively support exporting to ONNX format. So we have to convert it first to a pytorch logistic model, by manually assigned it's weight and bias to what we just trained in encrypted model, and then export it using pytorch's api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "JWp-LmABHHj8"
      },
      "outputs": [],
      "source": [
        "model_to_EZKL = LogisticModel(n_features)\n",
        "model_to_EZKL.linear.weight.data = torch.tensor([encrypted_logistic.weight])\n",
        "model_to_EZKL.linear.bias.data = torch.tensor(encrypted_logistic.bias)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXAR9J2WHIfv",
        "outputId": "ce728701-54cc-4467-93f8-196cf455f065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Requirement already satisfied: ezkl in /usr/local/lib/python3.10/dist-packages (2.4.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install ezkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aggrx7HYPFRg"
      },
      "source": [
        "# EZKL jumped in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExEFD0qO2sR",
        "outputId": "f8a10278-aa85-47c4-cfc5-f9bc47270b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define the path of all the necessary file\n",
        "import os\n",
        "import ezkl\n",
        "import json\n",
        "import onnx\n",
        "\n",
        "# set up some path\n",
        "model_path = os.path.join('network.onnx')\n",
        "compiled_model_path = os.path.join('network.compiled')\n",
        "pk_path = os.path.join('test.pk')\n",
        "vk_path = os.path.join('test.vk')\n",
        "settings_path = os.path.join('settings.json')\n",
        "srs_path = os.path.join('kzg.srs')\n",
        "witness_path = os.path.join('witness.json')\n",
        "data_path = os.path.join('input.json')\n",
        "\n",
        "\n",
        "# # After training, export to onnx (network.onnx) and create a data file (input.json)\n",
        "x = torch.randn([1, n_features], dtype=torch.float32)\n",
        "\n",
        "\n",
        "# print(x)\n",
        "\n",
        "    # Export the model\n",
        "\n",
        "model = model_to_EZKL\n",
        "\n",
        "#set model to eval model\n",
        "model.eval()\n",
        "\n",
        "torch.onnx.export(model,               # model being run\n",
        "                  x,                   # model input (or a tuple for multiple inputs)\n",
        "                  model_path,            # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})\n",
        "\n",
        "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
        "\n",
        "data_json = dict(input_data = [data_array])\n",
        "\n",
        "json.dump( data_json, open(data_path, 'w' ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "OlFWqkVDPJGv"
      },
      "outputs": [],
      "source": [
        "py_run_args = ezkl.PyRunArgs()\n",
        "\n",
        "#ZKP will hide information about user input, and model's parameters\n",
        "py_run_args.input_visibility = \"private\"\n",
        "py_run_args.output_visibility = \"public\"\n",
        "py_run_args.param_visibility = \"fixed\"\n",
        "\n",
        "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
        "\n",
        "assert res == True\n",
        "\n",
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True\n",
        "\n",
        "res = ezkl.get_srs(srs_path, settings_path)\n",
        "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "7WBMyH5TWLSC"
      },
      "outputs": [],
      "source": [
        "# HERE WE SETUP THE CIRCUIT PARAMS\n",
        "# WE GOT KEYS\n",
        "# WE GOT CIRCUIT PARAMETERS\n",
        "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
        "\n",
        "\n",
        "\n",
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMuXBCifZ35g",
        "outputId": "791c5140-b808-47f7-924e-a38abb716c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instances': [[[8895048820941913435, 12590578388187041751, 10644156957292843428, 485414809211466155]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
          ]
        }
      ],
      "source": [
        "# GENERATE A PROOF\n",
        "\n",
        "\n",
        "proof_path = os.path.join('test.pf')\n",
        "\n",
        "res = ezkl.prove(\n",
        "        witness_path,\n",
        "        compiled_model_path,\n",
        "        pk_path,\n",
        "        proof_path,\n",
        "        srs_path,\n",
        "        \"single\",\n",
        "    )\n",
        "\n",
        "print(res)\n",
        "assert os.path.isfile(proof_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glz3dAOiZ7Gr",
        "outputId": "a79262c6-dc3a-4125-f955-ec3794ae1343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "verified\n"
          ]
        }
      ],
      "source": [
        "# VERIFY IT\n",
        "\n",
        "res = ezkl.verify(\n",
        "        proof_path,\n",
        "        settings_path,\n",
        "        vk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "print(\"verified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdBNtUSraotF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
